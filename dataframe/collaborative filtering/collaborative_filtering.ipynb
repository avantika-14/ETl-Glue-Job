{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ONdAi6dyu5",
        "outputId": "742e0a03-caca-485a-b1c1-934f392c68b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello workd\n"
          ]
        }
      ],
      "source": [
        "print(\"hello workd\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxv7w_2y2bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "outputId": "d3f03355-6d14-4a2b-fdcd-6c361558c5da"
      },
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "os.environ[\"java_home\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"spark_home\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.\u001b[0m\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [2 InRelease 2,588 B/129\u001b[0m\r                                                                               \rIgn:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 30.1 kB/129 kB 23%] [Connected to ppa.lau\u001b[0m\r                                                                               \rGet:4 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,553 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,171 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,133 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,867 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,423 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,447 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,963 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Fetched 16.0 MB in 2s (8,244 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "All packages are up to date.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.7 (from pyspark)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=a00498b5a45bb07682a57b3769bb430828c7fbe7d3095069aa945d51abf46b3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.7 pyspark-3.5.2\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79f9740d06a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://705184ccae01:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.sql.functions import col,explode\n",
        "spark = SparkSession.builder.appName(\"Collaborative filtering\").getOrCreate()"
      ],
      "metadata": {
        "id": "OH5mwFC4Rzix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moviesDF = spark.read.options(header=\"True\", inferSchema=\"True\").csv(\"/content/movies.csv\")\n",
        "ratingsDF = spark.read.options(header=\"True\", inferSchema=\"True\").csv(\"/content/ratings.csv\")"
      ],
      "metadata": {
        "id": "VijRRxABSYHr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(moviesDF)\n",
        "display(ratingsDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "WpeEeaigee4U",
        "outputId": "f3d2787f-b877-4d18-8fbe-6c349c282027"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[movieId: int, title: string, genres: string]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratingsDF.join(moviesDF, 'movieId', 'left')"
      ],
      "metadata": {
        "id": "MFrqGcDgeidv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train, test) = ratings.randomSplit([0.8,0.2])"
      ],
      "metadata": {
        "id": "y1VSl0Jlemdr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3vicq7TepPG",
        "outputId": "3314580d-fc41-44b0-d2b7-4c1630f1c2f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100836"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.count())\n",
        "train.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD1n7tveescy",
        "outputId": "fc204e59-fbdf-4bab-faac-4229fbe03782"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80557\n",
            "+-------+------+------+----------+----------------+--------------------+\n",
            "|movieId|userId|rating| timestamp|           title|              genres|\n",
            "+-------+------+------+----------+----------------+--------------------+\n",
            "|      1|     5|   4.0| 847434962|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|     7|   4.5|1106635946|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    15|   2.5|1510577970|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    18|   3.5|1455209816|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    31|   5.0| 850466616|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    32|   3.0| 856736119|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    33|   3.0| 939647444|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    40|   5.0| 832058959|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    43|   5.0| 848993983|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    44|   3.0| 869251860|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    45|   4.0| 951170182|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    46|   5.0| 834787906|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    50|   3.0|1514238116|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    54|   3.0| 830247330|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    63|   5.0|1443199669|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    64|   4.0|1161520134|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    66|   4.0|1104643957|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    71|   5.0| 864737933|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    73|   4.5|1464196374|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    76|   0.5|1439165548|Toy Story (1995)|Adventure|Animati...|\n",
            "+-------+------+------+----------+----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test.count())\n",
        "test.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4133bQmevVK",
        "outputId": "48432663-6ea0-40f1-e1e5-8b8761b28a47"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20279\n",
            "+-------+------+------+----------+----------------+--------------------+\n",
            "|movieId|userId|rating| timestamp|           title|              genres|\n",
            "+-------+------+------+----------+----------------+--------------------+\n",
            "|      1|     1|   4.0| 964982703|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    17|   4.5|1305696483|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    19|   4.0| 965705637|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    21|   3.5|1407618878|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    27|   3.0| 962685262|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    57|   5.0| 965796031|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    68|   2.5|1158531426|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|    93|   3.0| 942767337|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   119|   3.5|1435942468|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   121|   4.0| 847656180|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   130|   3.0| 832589610|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   134|   3.0| 832841103|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   141|   4.0|1513130643|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   153|   2.0|1525548642|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   160|   4.0| 971115026|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   166|   5.0|1189980529|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   169|   4.5|1059427918|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   185|   4.0|1044311830|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   206|   5.0| 850763267|Toy Story (1995)|Adventure|Animati...|\n",
            "|      1|   220|   5.0|1230055565|Toy Story (1995)|Adventure|Animati...|\n",
            "+-------+------+------+----------+----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "als model -  is a popular algorithm used for collaborative filtering in recommendation systems\n"
      ],
      "metadata": {
        "id": "hzDloJ0Ce2cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "als = ALS(userCol = \"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative=True,implicitPrefs=False, coldStartStrategy=\"drop\")\n",
        "#usercol - refers to the user\n",
        "#itemcol - refers to the item selected or the item of which recommendation should be made\n",
        "#ratingcol - the parameter according to which ratings are defined\n",
        "#nonnegative - consideration of negative ratings\n",
        "#implicitperfs - refers to the implicit or explicit dataset\n",
        "#colstartstrategy - dropping the users with no ratings"
      ],
      "metadata": {
        "id": "vBUjOsraeyP0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hyperparameter tuning and cross validation"
      ],
      "metadata": {
        "id": "Ap4MPDQAe6Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning is the process of finding the best settings for the parts of a machine learning model that you have to decide before training\n",
        "#When tuning hyperparameters, you find the best combination of hyperparameters that result in the highest performance of your model.\n",
        "#To do this reliably, you use cross-validation to evaluate the performance of each combination of hyperparameter"
      ],
      "metadata": {
        "id": "kofzHU3ge11z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = ParamGridBuilder() \\\n",
        "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
        "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
        "            .build()\n",
        "\n",
        "#is a utility in PySpark's MLlib that helps you create a grid of hyperparameters for model tuning, particularly for use with\n",
        "#this will create 4*4 = 16 models with all combinations of parameters with values and then refer to the best module using cross validator\n",
        "#rank parameter, number of features used in the model, model will be evaluated based on the values in the list\n",
        "#regulizer parameter, which prevents the model from overfitting"
      ],
      "metadata": {
        "id": "r36GAqi3e_K8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(\n",
        "           metricName=\"rmse\",     #this shows the parameters with which evaluation should be performed\n",
        "           labelCol=\"rating\",     #rmse, refers to root mean square error\n",
        "           predictionCol=\"prediction\")\n",
        "#regression evaluator along with param grid builder goes for cross validator"
      ],
      "metadata": {
        "id": "H-D4LFRtfC6p"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
        "#to get the optimised or best cross validator"
      ],
      "metadata": {
        "id": "vcsenQynfFjx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cv.fit(train)\n",
        "best_model = model.bestModel #getting the best models created inside param grid\n",
        "test_predictions = best_model.transform(test)\n",
        "RMSE = evaluator.evaluate(test_predictions)\n",
        "print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7KuBaBfH1L",
        "outputId": "02902140-8bed-4e6c-b832-69013aa2944c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8760148688962565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YlQVVYafKZ0",
        "outputId": "50f492bf-bc6e-4a44-d54e-002dc26abb24"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8760148688962565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations = best_model.recommendForAllUsers(5)\n",
        "#it will recommend top 5 best models for users based on ratings for users"
      ],
      "metadata": {
        "id": "3awmuOoQfQbi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = recommendations\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "i3QD5SWMfXKw",
        "outputId": "55722598-c9ab-4b94-ae0b-1111cdeb2dde"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, recommendations: array<struct<movieId:int,rating:float>>]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.withColumn(\"movieid_rating\", explode(\"recommendations\"))\n",
        "display(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FEOP4hYofRRc",
        "outputId": "aecc15df-f705-4ac3-c5dc-e659424061ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, recommendations: array<struct<movieId:int,rating:float>>, movieid_rating: struct<movieId:int,rating:float>]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df2.select(\"userId\", col(\"movieid_rating.movieId\"), col(\"movieid_rating.rating\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YfaOq4TDfdcp",
        "outputId": "0509e0a9-47ce-46e8-858d-273f22c30c08"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movieId: int, rating: float]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qEjzaGRr5cI"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}